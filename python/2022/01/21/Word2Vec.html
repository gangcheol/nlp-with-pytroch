<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Word Embedding | Natural Language Processing with PyTorch</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Word Embedding" />
<meta name="author" content="이강철" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="NLP" />
<meta property="og:description" content="NLP" />
<link rel="canonical" href="https://gangcheol.github.io/nlp-with-pytroch/python/2022/01/21/Word2Vec.html" />
<meta property="og:url" content="https://gangcheol.github.io/nlp-with-pytroch/python/2022/01/21/Word2Vec.html" />
<meta property="og:site_name" content="Natural Language Processing with PyTorch" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-01-21T00:00:00-06:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Word Embedding" />
<script type="application/ld+json">
{"url":"https://gangcheol.github.io/nlp-with-pytroch/python/2022/01/21/Word2Vec.html","@type":"BlogPosting","headline":"Word Embedding","dateModified":"2022-01-21T00:00:00-06:00","datePublished":"2022-01-21T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://gangcheol.github.io/nlp-with-pytroch/python/2022/01/21/Word2Vec.html"},"author":{"@type":"Person","name":"이강철"},"description":"NLP","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/nlp-with-pytroch/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://gangcheol.github.io/nlp-with-pytroch/feed.xml" title="Natural Language Processing with PyTorch" /><link rel="shortcut icon" type="image/x-icon" href="/nlp-with-pytroch/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/nlp-with-pytroch/">Natural Language Processing with PyTorch</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/nlp-with-pytroch/about/">About Me</a><a class="page-link" href="/nlp-with-pytroch/search/">Search</a><a class="page-link" href="/nlp-with-pytroch/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Word Embedding</h1><p class="page-description">NLP</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-01-21T00:00:00-06:00" itemprop="datePublished">
        Jan 21, 2022
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">이강철</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      5 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/nlp-with-pytroch/categories/#python">python</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/gangcheol/nlp-with-pytroch/tree/master/_notebooks/2022-01-21-Word2Vec.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/nlp-with-pytroch/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/gangcheol/nlp-with-pytroch/master?filepath=_notebooks%2F2022-01-21-Word2Vec.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/nlp-with-pytroch/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/gangcheol/nlp-with-pytroch/blob/master/_notebooks/2022-01-21-Word2Vec.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/nlp-with-pytroch/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
          <div class="px-2">
  <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Fgangcheol%2Fnlp-with-pytroch%2Fblob%2Fmaster%2F_notebooks%2F2022-01-21-Word2Vec.ipynb" target="_blank">
      <img class="notebook-badge-image" src="/nlp-with-pytroch/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
  </a>
</div>

        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h1"><a href="#WordEmbedding">WordEmbedding </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Word2Vec">Word2Vec </a>
<ul>
<li class="toc-entry toc-h3"><a href="#CBOW">CBOW </a>
<ul>
<li class="toc-entry toc-h4"><a href="#가중치--행렬-갱신">가중치  행렬 갱신 </a></li>
<li class="toc-entry toc-h4"><a href="#Summary">Summary </a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#Skip-gram">Skip-gram </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Negative-Sampling">Negative Sampling </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-01-21-Word2Vec.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="WordEmbedding">
<a class="anchor" href="#WordEmbedding" aria-hidden="true"><span class="octicon octicon-link"></span></a>WordEmbedding<a class="anchor-link" href="#WordEmbedding"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>1</code>. 차원의 저주(Curse of Dimensionality) : 수학적 공간 차원(=변수 개수)이 늘어나면서, 문제 계산법이 지수적으로 커지는 상황</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>만약 $x=[1,2,3,4,5],\, y= [0,0,0,0,0]\to (X,Y)$ 을 표현한다고 하자</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>아래와 같이 1차원 상에서 표현되는 정보를 2차원 상에서 표현하게되어 설명 공간이 $5^2 =25$가 된 것이다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>이러한 경우를 차원의 저주라고 하며 이는 모델링 과정에서 저장 공간과 처리 시간이 불필요하게 증가됨을 의미한다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>이러한 문제점은 위와 같은 $(X,Y)$이산형 확률분포에서 결합분포를 구할 때 발생한다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>또한 이산형 변수들이 다양한 값$(0,1,2\dots 145748)$을 가질 경우 같은 길이의 두 문자열에서 거리를 측정하는 척도인 <strong>"해밍 거리"</strong>의 값이 거의 최댓값에 이르게 된다. [1]</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline 
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span> <span class="o">=</span><span class="n">axes</span>

<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"1-dimensional"</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">"off"</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"2-dimensional"</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>이러한 문제점을 해결하기 위해 NLP 분야에서는 단어를 저차원에 표현하기 위한 <strong>"워드 임베딩(Word Embedding)"</strong>을 제안하였다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>기존의 통계적인 방법이 단어의 출현 빈도에 집중 한다면 워드 임베딩은 서로 유사한 단어들 간 유사성을 포착하는데 집중한다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>-</code> 가정 : 유사한 의미를 가진 단어는 유사한 문맥안에서 발견된다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>-</code> 가정의 해석 : 유사한 의미를 가진 단어들은 유사한 단어 벡터를 가진다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>-</code> 이점 : 이웃된 단어들의 단어 벡터들을 학습하여 단어간 유사성을 도출해낼 수 있다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p>example 1 :'man' + 'royal' = 'king'</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>이제 이러한 임베딩 기법 중 하나인 <strong>"Word2Vec"</strong> 기법을 소개한다. [2]</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Word2Vec">
<a class="anchor" href="#Word2Vec" aria-hidden="true"><span class="octicon octicon-link"></span></a>Word2Vec<a class="anchor-link" href="#Word2Vec"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>워드 "<strong>Word2Vec</strong>" 중 가장 대표적인 방법으로 <strong>"CBOW"</strong>, <strong>"skip-gram"</strong> 이 존재한다.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="CBOW">
<a class="anchor" href="#CBOW" aria-hidden="true"><span class="octicon octicon-link"></span></a>CBOW<a class="anchor-link" href="#CBOW"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>주변 단어를 이용하여 중심단어를 예측한다.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>주어진 문맥에서 window size $k$ 를 적용해 target word 양옆에 $k$개의 단어들을 이용하여 조건부 확률을 계산한다. (편의상 k=1 이라고 설정) </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>
<code>프라닭</code> 이라는 단어를 예측한다고 가정한다.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>문장1</code>: 금요일 밤에 <code>프라닭</code>은 못참지</p>
<p><code>문장2</code>: 불금인데 교촌치킨 에 맥주?</p>
<p><code>단어</code> : [ "금요일", "밤", "프라닭","불금", "교촌치킨", "맥주" ] $\to Word \in R^{6 \times 6}$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>문장의 개수는 $j=2$, 단어의 개수는 총 $i=6$, 축소할 임베딩 차원의 개수는 $n=3$ 으로 설정하자.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>차원축소를 위해 생성되는 임베딩(=가중치) 행렬 $W \in R^{6\times 3}$ 으로 파이토치 기준 $N(0,1)$에서 생성된다.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>목적 1 : $Word \in R^{6 \times 6} \to W \in R^{6\times 3}$</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>목적 2 : 단어간 의미적 유사성을 포착하기 위한 임베딩 행렬 갱신 $W^{t} \to W^{t+1} $</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>1</code>. one-hot vector $Word \in R^{6 \times 6}$ 생성</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">index</span> <span class="o">=</span> <span class="p">[</span> <span class="s2">"금요일"</span><span class="p">,</span> <span class="s2">"밤"</span><span class="p">,</span> <span class="s2">"프라닭"</span><span class="p">,</span><span class="s2">"불금"</span><span class="p">,</span> <span class="s2">"교촌치킨"</span><span class="p">,</span> <span class="s2">"맥주"</span> <span class="p">]</span>

<span class="n">word1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">word2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">word3</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">word4</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">word5</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">word6</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>

<span class="n">one_hot</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">word1</span><span class="p">,</span><span class="n">word2</span><span class="p">,</span><span class="n">word3</span><span class="p">,</span><span class="n">word4</span><span class="p">,</span><span class="n">word5</span><span class="p">,</span><span class="n">word6</span><span class="p">],</span><span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">)</span>
<span class="n">one_hot</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>금요일</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>밤</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>프라닭</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>불금</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>교촌치킨</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>맥주</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>2</code>. 임베딩(가중치) 행렬 생성 $W \in R^{6\times 3}$</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">W</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"W1"</span><span class="p">,</span><span class="s2">"W2"</span><span class="p">,</span><span class="s2">"W3"</span><span class="p">])</span>
<span class="n">W</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>W1</th>
      <th>W2</th>
      <th>W3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>금요일</th>
      <td>-0.946677</td>
      <td>-0.964799</td>
      <td>-2.236172</td>
    </tr>
    <tr>
      <th>밤</th>
      <td>1.481341</td>
      <td>0.678401</td>
      <td>-1.239748</td>
    </tr>
    <tr>
      <th>프라닭</th>
      <td>-0.855941</td>
      <td>0.556102</td>
      <td>0.330505</td>
    </tr>
    <tr>
      <th>불금</th>
      <td>0.316146</td>
      <td>-1.791996</td>
      <td>-0.307091</td>
    </tr>
    <tr>
      <th>교촌치킨</th>
      <td>1.289018</td>
      <td>-1.415381</td>
      <td>0.418707</td>
    </tr>
    <tr>
      <th>맥주</th>
      <td>1.106920</td>
      <td>0.051748</td>
      <td>0.478479</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>3</code>. $\widehat W_{프라닭} = \frac {W_{밤} + W_{불금}} {2}   = [0.89,-0.55,0.77]$</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">W_1</span> <span class="o">=</span> <span class="nb">list</span><span class="p">((</span><span class="n">W</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">"밤"</span><span class="p">]</span> <span class="o">+</span> <span class="n">W</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">"불금"</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
<span class="n">W_1</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[0.8987433793584608, -0.5567973759616802, -0.7734197905021276]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>4</code>.  $ Z = \widehat W_{프라닭} \times  W^T = $ [ 1.42,  1.91, -1.33,  1.52,  1.62,  0.6 ]</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">W_1</span><span class="p">),</span><span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>
<span class="n">z</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([ 1.42,  1.91, -1.33,  1.52,  1.62,  0.6 ])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>5</code>. $\hat y$ 계산</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\hat y=softmax(Z) = [0.18,\,\,0.30,\,\,0.01,\,\,0.20,\,\,0.22,\,\,0.08]$</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">softmax</span>
<span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">so</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">"y_hat"</span><span class="p">:</span> <span class="n">softmax</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="s2">"y"</span> <span class="p">:</span> <span class="n">y</span><span class="p">},</span><span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">)</span>
<span class="n">so</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>y_hat</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>금요일</th>
      <td>0.182270</td>
      <td>0</td>
    </tr>
    <tr>
      <th>밤</th>
      <td>0.299486</td>
      <td>0</td>
    </tr>
    <tr>
      <th>프라닭</th>
      <td>0.011647</td>
      <td>1</td>
    </tr>
    <tr>
      <th>불금</th>
      <td>0.202155</td>
      <td>0</td>
    </tr>
    <tr>
      <th>교촌치킨</th>
      <td>0.224158</td>
      <td>0</td>
    </tr>
    <tr>
      <th>맥주</th>
      <td>0.080284</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="가중치--행렬-갱신">
<a class="anchor" href="#%EA%B0%80%EC%A4%91%EC%B9%98--%ED%96%89%EB%A0%AC-%EA%B0%B1%EC%8B%A0" aria-hidden="true"><span class="octicon octicon-link"></span></a>가중치  행렬 갱신<a class="anchor-link" href="#%EA%B0%80%EC%A4%91%EC%B9%98--%ED%96%89%EB%A0%AC-%EA%B0%B1%EC%8B%A0"> </a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>위와 같은 과정을 모든 단어에 대해 수행하여 크로스 엔트로피 함수를 적용한 $loss$를 계산한다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>1</code>.   $loss=-\sum_{i=1}^6 y_i\log  p_i$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>2</code>.$loss$를 최소화 하는 최적의 파라미터 $\theta$를 구함 $\to\frac {\partial loss}{\partial p} $</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>3</code>. example $W_{밤},W_{불금}$ 업데이트($\alpha $ :  learning rate)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$W_{밤}^{t+1} = W_{밤}^t + \left(\,\alpha\,\times \theta\,\right)$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$W_{불금}^{t+1} = W_{불금}^t + \left(\,\alpha\,\times \theta\,\right)$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Summary">
<a class="anchor" href="#Summary" aria-hidden="true"><span class="octicon octicon-link"></span></a>Summary<a class="anchor-link" href="#Summary"> </a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>중심단어 벡터 $W_c$가 있고, 주변 단어 벡터 $W_o$가 있다고 하자.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>$t+1$ 시점에서 $t$ 시점의 결과를 반영하여 단어벡터 $W_{o}$를 갱신한다.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>$W^{t+1}_{o}  =W^{t}_{o} + \alpha \times [l(\theta_{c})]$</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>타겟단어 예측시 사용되는 수식 [4]</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>
$$P(w_O|w_I) = \frac{\exp\,({v^{\prime}_{w_O}}^Tv_{w_{I}})} {\sum_{w=1}^W \exp\,({v^{\prime}_w}^Tv_{w_{I}}) } $$
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>
$$I \,\,:\,\,Input,\,\,O\,\,:\,\, Output$$
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>
$$W : number\,\,\, of\,\,\, Word$$
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Skip-gram">
<a class="anchor" href="#Skip-gram" aria-hidden="true"><span class="octicon octicon-link"></span></a>Skip-gram<a class="anchor-link" href="#Skip-gram"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Skip-gram의 경우 CBOW와 달리 중심단어를 가지고 주변단어를 예측하는 과정이다.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>따라서 CBOW의 <code>3</code>번째 단계 window-size내의 주변 단어들의 합을 평균 내는 과정이 생략된다.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>이러한 부분을 빼면 CBOW와 동일하다.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Skip-gram과 CBOW의 경우 아래와 같은 수식을 최대화 하는 것을 목표로 한다. (베르누이분포의 MLE 를 생각해보장) [4]</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>베르누이분포의 MLE와 크로스 엔트로피 손실함수의 최소값 파라미터를 구하는 것이 동치라고 생각해보자.(이 부분 다시 증명)</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>
$$\frac 1T \sum_{t=1}^T \sum_{-c\leq j\leq c, j\neq 0} y_{t+j}\log p\left(w_{t+j}|w_t\right),\quad[4]$$
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>
$$T : \mathrm{ number\,\, of\,\, traning\,\, word}, \quad c : \mathrm{the\,\, size\,\, of\,\, training\,\, context\,\, (=window)}  $$
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>사실상 $y_{t+j}$ 는 예측하고자 하는 target단어가 아니면 0, 맞으면 1이므로 위식은 다시 아래와 같이 바꿔 쓸 수 있다. </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>
$$\frac 1T \sum_{t=1}^T \sum_{-c\leq j\leq c, j\neq 0} \log p\left(w_{t+j}|w_t\right),\quad[4]$$
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Negative-Sampling">
<a class="anchor" href="#Negative-Sampling" aria-hidden="true"><span class="octicon octicon-link"></span></a>Negative Sampling<a class="anchor-link" href="#Negative-Sampling"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>
$$ P(w_O|w_I) = \frac{\exp\,({v^{\prime}_{w_O}}^Tv_{w_{I}})} {\sum_{w=1}^W \exp\,({v^{\prime}_w}^Tv_{w_{I}}) }$$
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>위와 같이 Word2Vec은 출력층이 내놓는 스코어 값에 소프트맥스 함수를 적용해 확률값으로 변환한 후 이를 정답과 비교해 <strong>"역전파(backpropagation)"</strong> 하는 구조이다.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>그런데 소프트맥스를 적용하려면 분모에 해당하는 값, 즉 중심(=input) 단어와 나머지 모든 단어의 내적을 한 뒤 이를 다시 $\exp$ 취해줘야한다.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>보통 전체 단어가 10만개 이상 주어지므로 계산량이 어마어마 해진다.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Negative Sampling은 소프트맥스 확률을 구할 때 전체 단어를 구하지 않고, 일부 단어만 뽑아서 계산을 하자는 아이디어다.[3][4]</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>사용자가 지정한 윈도우 사이즈 내에 등장하지 않는 단어(Negative saple)을 5~20개 정도 뽑고, 이를 우리가 예측하고자 하는 타겟 단어와 합쳐 전체 단어처럼 소프트맥스 확률을 구하는 것이다.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>보통 5~20 ($k$) 개 정도 뽑는데, 이는 만약 윈도우 사이즈가 5일 경우 최대 25개의 단어를 대상으로만 소프트맥스 확률을 계산하고, 파라미터 업데이트도 25개 대상으로만 이뤄진다는 이야기이다.[3][4]</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>
$$ P(w_O|w_I) = \frac{\exp\,({v^{\prime}_{w_O}}^Tv_{w_{I}})} {\sum_{i=1}^k \exp\,({v^{\prime}_w}^Tv_{w_{I}}) }$$
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>특정 단어가 negative sampliing 될 확률 $P_n(w_i) $은 다음과 같다. $P_n(w_i)$는 <code>free parameter</code>로 선행연구에 의하면 단일 단어인 $\mathrm{unigram-distribution}$의 경우 $f(w_i)^{3/4}$일 때 뛰어난 성능을 보였다고 한다.[4]</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>
$$ P_n(w_i)=\frac {f(w_i)^{3/4}}{\sum_{j=0}^n f(w_j)^{3/4}}$$
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$$f(w_i) =  (해당\,\,단어\,\,빈도\,\, /\,\,전체\,\, 단어\,\, 수)$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>참고문헌</p>
<p>skip-gram : <a href="https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/30/word2vec/">https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/30/word2vec/</a></p>
<p>[1] : <a href="chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/viewer.html?pdfurl=https%3A%2F%2Fwww.jmlr.org%2Fpapers%2Fvolume3%2Ftmp%2Fbengio03a.pdf&amp;clen=140095&amp;chunk=true">Bengio, Yoshua, et al. "A neural probabilistic language model." Journal of machine learning research 3.Feb (2003): 1137-1155.</a></p>
<p>[2] : <a href="https://ieeexplore.ieee.org/abstract/document/8416973">Young, Tom, et al. "Recent trends in deep learning based natural language processing." ieee Computational intelligenCe magazine 13.3 (2018): 55-75.</a></p>
<p>[3] : <a href="https://arxiv.org/abs/1301.3781">Mikolov, Tomas, et al. "Efficient estimation of word representations in vector space." arXiv preprint arXiv:1301.3781 (2013).</a></p>
<p>[4] : <a href="chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/viewer.html?pdfurl=https%3A%2F%2Fproceedings.neurips.cc%2Fpaper%2F2013%2Ffile%2F9aa42b31882ec039965f3c4923ce901b-Paper.pdf&amp;clen=111997">Mikolov, Tomas, et al. "Distributed representations of words and phrases and their compositionality." Advances in neural information processing systems. 2013.</a></p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="gangcheol/nlp-with-pytroch"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/nlp-with-pytroch/python/2022/01/21/Word2Vec.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/nlp-with-pytroch/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/nlp-with-pytroch/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/nlp-with-pytroch/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/gangcheol" target="_blank" title="gangcheol"><svg class="svg-icon grey"><use xlink:href="/nlp-with-pytroch/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
