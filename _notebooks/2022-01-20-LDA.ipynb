{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f33170da",
   "metadata": {},
   "source": [
    "# LDA\n",
    "> \"NLP\"\n",
    "\n",
    "- toc:true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: 이강철\n",
    "- categories: [python]\n",
    "- hide: false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c01d49",
   "metadata": {},
   "source": [
    "# 1.  Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0959b9",
   "metadata": {},
   "source": [
    "토픽 모델링은 수집된 문서들을 비지도 방식으로 분류하는 방법이다.[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fce687",
   "metadata": {},
   "source": [
    "Latent Dirichlet Allocation (LDA)는 문서 집합들을 특정한 주제를 가지는 토픽들로 분류하기 위한 계층적 확률 모델로 다양한 분야에서 많이 사용되는 분야이다. 특히 컴퓨터 비전분야에서 두드러지는데 주석이나 라벨이 부착된 이미지를 분류를 하는 등 다양한 문제들을 처리하기 위해 사용된다.[2] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbbabda",
   "metadata": {},
   "source": [
    "LDA의 기본 가정은 여러 단어가 섞여 토픽을 이루고, 여러 토픽이 섞여 문서를 이룬다고 본다. 즉, 문서를  토픽들의 혼합체로 보는 것이다. 이는 각 문서의 내용(단어)이 서로 겹치게`overlap `해 둘 수 있다.[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0f99b8",
   "metadata": {},
   "source": [
    "## 1-1. 모든 문서는 토픽들의 혼합체이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c6c8a9",
   "metadata": {},
   "source": [
    "각 문서에는 몇 가지 토픽에서 나온 단어가 특정 비율로 포함되어 있다고 생각한다. 예를 들어 2개의 토픽을 가지는 문서 집합이 있다고 하자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993e3356",
   "metadata": {},
   "source": [
    "> example<br><br> 문서 1 : 토픽 A 90%, 토픽 B 10% $\\to$ 토픽 A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea98780b",
   "metadata": {},
   "source": [
    "> example<br><br> 문서 2 : 토픽 A 30%, 토픽 B 70% $\\to$ 토픽 B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e90851",
   "metadata": {},
   "source": [
    "위 같은 경우 우리는 문서 1에서는 토픽 A가 90%를 차지하고 토픽 B가 10%를 차지하는 반면에, 문서 2에서는 토픽 A가 30%를 차지하고 토픽 B가 70%를 차지한다는 식으로 말할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e267ec8a",
   "metadata": {},
   "source": [
    "## 1-2.  모든 토픽은 단어들의 혼합체이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec51106",
   "metadata": {},
   "source": [
    "예를 들어 `정치`와 `음식`이라는 두 가지 토픽이 존재한다고 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ef528f",
   "metadata": {},
   "source": [
    "정치 토픽에서 가장 흔히 사용되는 단어는 `대통령`, `TV`, `국회의원`과 같은 단어가 될 수 있지만 음식 토픽에서 가장 흔히 사용되는 용어는 `맛집`, `TV`, `불고기` 같은 단어가 될 수 있는 것이다. 만약 정치라는 토픽으로 분류된 아래와 같은 문서가 있다고 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b42374",
   "metadata": {},
   "source": [
    "> example <br><br>국회위원 A씨가 `TV`에서 `맛집`으로 소문난 B라는 식당에 들려서 식사를 맛있게 했습니다. 또 ~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1367ec43",
   "metadata": {},
   "source": [
    "위 같은 경우 해당 문서는 `정치`라는 토픽으로 분류가 되었지만 `음식`이라는 토픽에 포함된 단어들도 포함하고 있다. 이는 앞서 말한 `overlap`을 뜻하며 각각의 문서들은 여러 토픽으로 구성되어 있음을 뜻한다. 또한 각각의 토픽들은 동일한 단어를 공유할 수 있음을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d453181",
   "metadata": {},
   "source": [
    "**\"토픽\"** 은 단어사전에 대한 확률분포를 따르기 때문에 LDA의 경우 확률적 토픽 모델이라고 불려진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48be2c3a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed23d392",
   "metadata": {},
   "source": [
    "# 2. Represnetation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4dd777",
   "metadata": {},
   "source": [
    "## 2-1. Notation 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd907f5c",
   "metadata": {},
   "source": [
    "![](LDA1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2012735b",
   "metadata": {},
   "source": [
    "$K$ : 지정된 토픽의 수, $D$ : 문서의 수, $N$ : $D$번째 문서의 단어 수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233d805e",
   "metadata": {},
   "source": [
    "$\\alpha, \\beta : \\mathrm{Hyper\\,\\, Parameter}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a269c0",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4904d7",
   "metadata": {},
   "source": [
    "![](LDA1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786a095f",
   "metadata": {},
   "source": [
    "$\\phi_k$ : $k$ 번째 토픽의 단어 비중 $\\to \\phi_k \\sim \\mathrm{Dir\\,(\\beta)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672464f4",
   "metadata": {},
   "source": [
    "$V: \\mathrm{Word\\, of\\, vocabulary}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dcc9b9",
   "metadata": {},
   "source": [
    "$$P(\\phi|\\beta) = \\frac {\\Gamma\\left(\\sum_{i=1}^V \\beta_i \\right)}{\\prod_{i=1}^k \\Gamma(\\beta_i)}\\phi_1^{\\beta_1-1}\\dots \\phi_V^{\\beta_V -1}\\,\\quad \\phi_i\\geq 0, \\sum_{i=1}^V \\phi_i=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf27b241",
   "metadata": {},
   "source": [
    "아래 토픽당  단어 비중을 확인하면 `Topic1`은 음식 `Topic2` 은 음악과 관련된 주제라고 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f319872f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>삼겹살</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>치킨</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>김치</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>음악</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic1  Topic2\n",
       "삼겹살     0.4     0.1\n",
       "치킨      0.3     0.0\n",
       "김치      0.2     0.0\n",
       "음악      0.1     0.9"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collapse-hide\n",
    "import pandas as pd\n",
    "topic = [\"Topic1\", \"Topic2\"]\n",
    "word = [\"삼겹살\",\"치킨\",\"김치\",\"음악\"]\n",
    "prob1 = [0.4,0.3,0.2,0.1]\n",
    "prob2 = [0.1,0.0,0.0,0.9]\n",
    "\n",
    "pd.DataFrame([prob1,prob2],index=topic,columns=word).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d014a94d",
   "metadata": {},
   "source": [
    "![](LDA1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82c78df",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2907e462",
   "metadata": {},
   "source": [
    "$\\theta_d$ ; $d$ 번째 문서가 가진 토픽 비중을 나타내는 벡터 $\\to \\theta_d \\sim \\mathrm{Dir}\\,(\\alpha), \\quad d \\in \\{1,\\dots D\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cc2b39",
   "metadata": {},
   "source": [
    "$$P(\\theta|\\alpha) = \\frac {\\Gamma\\left(\\sum_{i=1}^K \\alpha_i \\right)}{\\prod_{i=1}^k \\Gamma(\\alpha_i)}\\theta_1^{\\alpha_1-1}\\dots \\theta_k^{\\alpha_k -1}\\,\\quad \\theta_i\\geq 0, \\sum_{i=1}^K \\theta_i=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8061cb13",
   "metadata": {},
   "source": [
    "문서당 토픽확률을 살펴보면 문서1과 3는 음식과 음악 두 토픽을 적절히 다루지만, 문서 2의 경우는 음식에 대한 토픽의 비중이 높은 것으로 보아 음식과 관련된 주제를 다루는 문서일 가능성이 높다고 판단할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5387c2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc1</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc2</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic1  topic2\n",
       "doc1     0.6     0.4\n",
       "doc2     0.9     0.1\n",
       "doc3     0.5     0.5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collapse-hide\n",
    "d = [\"doc1\",\"doc2\",\"doc3\"]\n",
    "topic = [\"topic1\",\"topic2\"]\n",
    "\n",
    "prob1 =[0.6,0.4]\n",
    "prob2 =[0.9,0.1]\n",
    "prob3 = [0.5,0.5]\n",
    "pd.DataFrame([prob1,prob2,prob3],index = d, columns = topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ef15d3",
   "metadata": {},
   "source": [
    "![](LDA1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586693b9",
   "metadata": {},
   "source": [
    "$Z_{d,n}$ : $d$번째 문서의 $n$ 번째 단어가 어떤 토픽에 해당하는지 할당해주는 역할을 한다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467b1477",
   "metadata": {},
   "source": [
    "다시 한번 언급하자면 $\\theta_d$는 문서당 토픽 비중이다. 즉 직관적으로 해석하자면 $Z_{d,n}$은 $d$번째 문서의 토픽 비중벡터가 주어졌을 때 $n$번째 단어가 어떤 토픽에 할당될 것인지 정해주는 역할을 수행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72de4143",
   "metadata": {},
   "source": [
    "$$x_i=z_{d,n} | \\theta_d  \\sim \\mathrm{Mult}\\,(\\theta_d)\\quad \\theta_d = \\left({p_1\\dots p_k}\\right), i \\in \\{1,\\dots k\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad54499",
   "metadata": {},
   "source": [
    "$$p_i = \\mathrm{topic\\, proportions\\,of\\, \\mathit{i}\\,th}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0660b2e",
   "metadata": {},
   "source": [
    "$$P(x_1,\\dots,x_k) = \\frac {m!}{\\prod_{i=1}^K x_i!}\\prod_{i=1}^{K} p_i^{x_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66618f7f",
   "metadata": {},
   "source": [
    "$$m : \\mathrm{sampling\\, frequency}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e52302d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc1</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc2</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic1  topic2\n",
       "doc1     0.6     0.4\n",
       "doc2     0.9     0.1\n",
       "doc3     0.5     0.5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collapse-hide\n",
    "d = [\"doc1\",\"doc2\",\"doc3\"]\n",
    "topic = [\"topic1\",\"topic2\"]\n",
    "\n",
    "prob1 =[0.6,0.4]\n",
    "prob2 =[0.9,0.1]\n",
    "prob3 = [0.5,0.5]\n",
    "pd.DataFrame([prob1,prob2,prob3],index = d, columns = topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e312c2",
   "metadata": {},
   "source": [
    "만약 2번째 문서의 1번째 단어가 어떤 토픽에 해당하는지가 궁금하다고 하자. $\\to Z_{2,1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cde81a5",
   "metadata": {},
   "source": [
    " 두 번째 문서의 경우 `Topic1`이 뽑힙 확률이 0.9 이므로 첫 번째 단어는 `Topic1`일 가능성이 높은 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53321ea",
   "metadata": {},
   "source": [
    "![](LDA1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bac64f5",
   "metadata": {},
   "source": [
    "$w_{d,n}$ : 문서에 등장하는 단어를 할당한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb4ca99",
   "metadata": {},
   "source": [
    "위 그림에서 확인할 수 있듯이 $W_{d,n}$은 $\\phi_k,z_{d,n}$에 영향을 받는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96462b64",
   "metadata": {},
   "source": [
    "다시 한번 언급하면 $\\phi_k$ 는 디리클레분포를 따르는 토픽내 단어 비중이다. $\\to \\phi_k \\sim \\mathrm{Dir\\,(\\beta)}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56c1345",
   "metadata": {},
   "source": [
    "또한 $z_{d,n}$은 $\\theta_d$를 조건부로하여 $d$번째 문서의 $n$ 번째 단어가 어떤 토픽에 해당하는지 할당해주는 역할을 한다.  $\\to x_i=z_{d,n} | \\theta_d  \\sim \\mathrm{Mult}\\,(\\theta_d)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4938e4dd",
   "metadata": {},
   "source": [
    "즉 $w_{d,n}$은 주어진 토픽내 단어 비중($\\phi_k$)과 $z_{d,n} | \\theta_d  \\sim \\mathrm{Mult}\\,(\\theta_d)$을 가지고 문서에 등장하는 단어를 할당해주는 역할을 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a745e6c1",
   "metadata": {},
   "source": [
    "$$z_{d,n} | \\theta_d  \\sim \\mathrm{Mult}\\, (\\theta_d)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78946703",
   "metadata": {},
   "source": [
    "$$w_{d,n}| z_{d,n},\\phi_{1:K} \\sim \\mathrm{Mult}\\,(\\phi_{z_{d,n}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ebf68f",
   "metadata": {},
   "source": [
    "만약 $w_{2,1}$을 구해본다고 생각하자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8019b142",
   "metadata": {},
   "source": [
    "실제로 두 번째 문서의 첫 번째 단어가 $Z_{2,1}$이 `topic1`에 할당 됐다고 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "589cc532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc1</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc2</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic1  topic2\n",
       "doc1     0.6     0.4\n",
       "doc2     0.9     0.1\n",
       "doc3     0.5     0.5"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collapse-hide\n",
    "d = [\"doc1\",\"doc2\",\"doc3\"]\n",
    "topic = [\"topic1\",\"topic2\"]\n",
    "\n",
    "prob1 =[0.6,0.4]\n",
    "prob2 =[0.9,0.1]\n",
    "prob3 = [0.5,0.5]\n",
    "pd.DataFrame([prob1,prob2,prob3],index = d, columns = topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace779ac",
   "metadata": {},
   "source": [
    "그렇다면 $w_{2,1}$ 삼겹살이 될 가능성이 가장 높다. `Topic1`의 분포($\\phi_1$) 가운데 삼겹살이 `0.4`로 가장 높기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf61321a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>삼겹살</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>치킨</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>김치</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>음악</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic1  Topic2\n",
       "삼겹살     0.4     0.1\n",
       "치킨      0.3     0.0\n",
       "김치      0.2     0.0\n",
       "음악      0.1     0.9"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collapse-hide\n",
    "import pandas as pd\n",
    "topic = [\"Topic1\", \"Topic2\"]\n",
    "word = [\"삼겹살\",\"치킨\",\"김치\",\"음악\"]\n",
    "prob1 = [0.4,0.3,0.2,0.1]\n",
    "prob2 = [0.1,0.0,0.0,0.9]\n",
    "\n",
    "pd.DataFrame([prob1,prob2],index=topic,columns=word).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252079b7",
   "metadata": {},
   "source": [
    "## 2-2.  Dirichlet Distriuibution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023c0146",
   "metadata": {},
   "source": [
    "**\"디리클레분포\"** 란 $k$ 차원의 실수 벡터 중 벡터의 요소가 양수이며 모든 요소를 더한 값이 1인 경우에 확률값이 정의되는 연속확률분포이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e498f03f",
   "metadata": {},
   "source": [
    "$$f\\left(\\mathbf {P}\\right) =\\frac {\\Gamma \\left( \\sum_{i=1}^k\\alpha_i\\right)}{\\prod_{i=1}^k\\Gamma \\left(\\alpha_i\\right)}\\times \\prod_{i=1}^kp_k^{\\alpha_k-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ef152a",
   "metadata": {},
   "source": [
    "$$\\mathbf{P} = \\left(p_1\\dots p_k \\right),\\quad \\sum_{i=1}^k p_i=1,\\quad \\alpha_i >0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361f0883",
   "metadata": {},
   "source": [
    "LDA에서는 토픽 내 단어 비중 $\\phi_k$와 문서 내 토픽 비중 $\\theta_d$가 각각 $\\alpha,\\beta$ 값을 입력 받아 디리클레분포를 따른다는 가정하에 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2faa40",
   "metadata": {},
   "source": [
    "디리클레분포의 경우 유한차원에서 충분통계량을 가지며 지수족에 속하고 켤레사전분포에 따른다고 알려져있다. 본 논문에서는 기존 LDA의 워드임베딩 방법을 결합하여 토픽 형성시 단어간 의미 연관성을 고려하는 것이 목적이므로 자세한 설명은 생략한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164c1562",
   "metadata": {},
   "source": [
    "## 2-3. LDA의 추론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f098ba",
   "metadata": {},
   "source": [
    "앞에서는 LDA의 잠재변수들이 어떤 역할을 하고 문서내 단어가 어떤식으로 할당이 되는지를 살펴보았다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45802cbf",
   "metadata": {},
   "source": [
    "이제는 관측값인 $w_{d,n}$을 가지고 잠재변수를 역으로 추정하는 과정을 설명한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e845be",
   "metadata": {},
   "source": [
    "![](LDA1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c03fc8",
   "metadata": {},
   "source": [
    "LDA의 목적은 관측값 $w_{d,n}$이 주어졌을 때 사후확률 $p\\left(\\phi, \\theta,z|w\\right)$를 최대로 만드는 $\\phi,\\theta,\\,z$를 찾는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257278fb",
   "metadata": {},
   "source": [
    "즉, 임의의 단어가 주어졌을 때 토픽 내 단어 확률($\\phi$), 문서 내 토픽 확률($\\theta$), 그리고 $z|\\theta \\sim \\mathrm{Mult\\,(\\theta)}$의 결합확률이 커지도록 해야하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3174a6e1",
   "metadata": {},
   "source": [
    "$$P(\\phi,\\theta,z|w) = \\frac {P(\\phi,\\theta,z,w)}{P(w)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bbcbcf",
   "metadata": {},
   "source": [
    "만약 김치라는 단어가 주어졌다고 하고 $\\phi_1$은 음식과 관련된 토픽 내 단어 확률벡터라고 하자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76ff24d",
   "metadata": {},
   "source": [
    "그렇다면 $\\phi_{1,김치}\\,\\,$의 값이 높을수록 우리가 LDA로 생성한 토픽이 합리적이라고 말할 수 있는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2c43c0",
   "metadata": {},
   "source": [
    "또 다른 예시를 들어보자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc73e34f",
   "metadata": {},
   "source": [
    "만약 다음과 같은 문장1($\\theta$) 과, $w=$[삼겹살, 목살, 냉면] 이 있다고 하자 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6b1488",
   "metadata": {},
   "source": [
    "> example  \"오늘 점심은 고기 뷔페가서 삼겹살, 목살을 먹고 냉면으로 마무리까지 했어!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf68927",
   "metadata": {},
   "source": [
    "그렇다면 $\\theta_{문장1,음식}$ 의 확률이 클수록 LDA로 생성한 토픽이 합리적이라고 설명할 수 있는 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8dadf0",
   "metadata": {},
   "source": [
    "그러나 $z,\\phi,\\theta$는 잠재변수로 직접 관찰하는 것이 불가능한 변수일 뿐더러 $P(w)$를 계산할 때 $\\phi, \\theta, z$를 모두 고려해야 하기 때문에 매우 어려운 과정이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e9bf18",
   "metadata": {},
   "source": [
    "이 때문에 LDA에서는 \"**깁스 샘플링**\" 방법을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a2f278",
   "metadata": {},
   "source": [
    "# 참고문헌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfbaa39",
   "metadata": {},
   "source": [
    "[1] : [Text Mining with R](https://www.tidytextmining.com/)\n",
    "\n",
    "[2] : [Blei, D., Carin, L., & Dunson, D. (2010). Probabilistic topic models. IEEE signal processing magazine, 27(6), 55-65.](https://ieeexplore.ieee.org/abstract/document/5563111)\n",
    "\n",
    "[3] : [Darling, William M. \"A theoretical and practical implementation tutorial on topic modeling and gibbs sampling.\" Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies. 2011.](https://scholar.google.com/scholar?hl=ko&as_sdt=0%2C5&q=A+Theoretical+and+Practical+Implementation+Tutorial+on+Topic+Modeling+and+Gibbs+Sampling&btnG=)\n",
    "\n",
    "[4] :  [Blei, David M., Andrew Y. Ng, and Michael I. Jordan. \"Latent dirichlet allocation.\" the Journal of machine Learning research 3 (2003): 993-1022.](https://scholar.google.com/scholar?hl=ko&as_sdt=0%2C5&q=Latent+Dirichlet+Allocation&btnG=)\n",
    "\n",
    "[5] : [백시온. \"한국어 토픽모델링을 위한 단어 임베딩 활용 가능성 탐색.\" 국내석사학위논문 서울대학교 대학원, 2019. 서울](http://www.riss.kr/search/detail/DetailView.do?p_mat_type=be54d9b8bc7cdb09&control_no=bee51790c400f190ffe0bdc3ef48d419&outLink=K)\n",
    "\n",
    "[6] : [Hankin, Robin KS. \"A generalization of the Dirichlet distribution.\" Journal of Statistical Software 33.11 (2010): 1-18.](https://scholar.google.com/scholar?hl=ko&as_sdt=0%2C5&q=A+Generalization+of+the+Dirichlet+Distribution&btnG=)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
