{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd9e9344",
   "metadata": {},
   "source": [
    "# 데이터 증강\n",
    "> \"NLP\"\n",
    "\n",
    "- toc:true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: 전북대학교 통계학과 이강철\n",
    "- categories: [python]\n",
    "- hide :false\n",
    "- published: true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa89f58d",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb0908c",
   "metadata": {},
   "source": [
    "* 본 코드는 EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks 를 한국어로 쓸 수 있도록 wordnet 부분만 교체한 프로젝트의 코드를 인용하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9b3bf2",
   "metadata": {},
   "source": [
    "* 원 데이터를 10, 5, 2 배수로 증가시켰다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f6a65c",
   "metadata": {},
   "source": [
    "# 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "305c3296",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:138: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<>:138: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "C:\\Users\\rkdcj\\AppData\\Local\\Temp/ipykernel_17464/3250283189.py:138: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  words = [word for word in words if word is not \"\"]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "wordnet = {}\n",
    "with open(\"wordnet.pickle\", \"rb\") as f:\n",
    "     wordnet = pickle.load(f)\n",
    "\n",
    "\n",
    "# 한글만 남기고 나머지는 삭제\n",
    "def get_only_hangul(line):\n",
    "    parseText= re.compile('/ ^[ㄱ-ㅎㅏ-ㅣ가-힣]*$/').sub('',line)\n",
    "\n",
    "    return parseText\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# Synonym replacement\n",
    "# Replace n words in the sentence with synonyms from wordnet\n",
    "########################################################################\n",
    "def synonym_replacement(words, n):\n",
    "    new_words = words.copy()\n",
    "    random_word_list = list(set([word for word in words]))\n",
    "    random.shuffle(random_word_list)\n",
    "    num_replaced = 0\n",
    "    for random_word in random_word_list:\n",
    "        synonyms = get_synonyms(random_word)\n",
    "        if len(synonyms) >= 1:\n",
    "            synonym = random.choice(list(synonyms))\n",
    "            new_words = [synonym if word == random_word else word for word in new_words]\n",
    "            num_replaced += 1\n",
    "        if num_replaced >= n:\n",
    "            break\n",
    "\n",
    "    if len(new_words) != 0:\n",
    "        sentence = ' '.join(new_words)\n",
    "        new_words = sentence.split(\" \")\n",
    "\n",
    "    else:\n",
    "        new_words = \"\"\n",
    "\n",
    "    return new_words\n",
    "\n",
    "\n",
    "def get_synonyms(word):\n",
    "    synomyms = []\n",
    "\n",
    "    try:\n",
    "        for syn in wordnet[word]:\n",
    "            for s in syn:\n",
    "                synomyms.append(s)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return synomyms\n",
    "\n",
    "########################################################################\n",
    "# Random deletion\n",
    "# Randomly delete words from the sentence with probability p\n",
    "########################################################################\n",
    "def random_deletion(words, p):\n",
    "    if len(words) == 1:\n",
    "        return words\n",
    "\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        r = random.uniform(0, 1)\n",
    "        if r > p:\n",
    "            new_words.append(word)\n",
    "\n",
    "    if len(new_words) == 0:\n",
    "        rand_int = random.randint(0, len(words)-1)\n",
    "        return [words[rand_int]]\n",
    "\n",
    "    return new_words\n",
    "\n",
    "########################################################################\n",
    "# Random swap\n",
    "# Randomly swap two words in the sentence n times\n",
    "########################################################################\n",
    "def random_swap(words, n):\n",
    "    new_words = words.copy()\n",
    "    for _ in range(n):\n",
    "        new_words = swap_word(new_words)\n",
    "\n",
    "    return new_words\n",
    "\n",
    "def swap_word(new_words):\n",
    "    random_idx_1 = random.randint(0, len(new_words)-1)\n",
    "    random_idx_2 = random_idx_1\n",
    "    counter = 0\n",
    "\n",
    "    while random_idx_2 == random_idx_1:\n",
    "        random_idx_2 = random.randint(0, len(new_words)-1)\n",
    "        counter += 1\n",
    "        if counter > 3:\n",
    "            return new_words\n",
    "\n",
    "    new_words[random_idx_1], new_words[random_idx_2] = new_words[random_idx_2], new_words[random_idx_1]\n",
    "    return new_words\n",
    "\n",
    "########################################################################\n",
    "# Random insertion\n",
    "# Randomly insert n words into the sentence\n",
    "########################################################################\n",
    "def random_insertion(words, n):\n",
    "    new_words = words.copy()\n",
    "    for _ in range(n):\n",
    "        add_word(new_words)\n",
    "\n",
    "    return new_words\n",
    "\n",
    "\n",
    "def add_word(new_words):\n",
    "    synonyms = []\n",
    "    counter = 0\n",
    "    while len(synonyms) < 1:\n",
    "        if len(new_words) >= 1:\n",
    "            random_word = new_words[random.randint(0, len(new_words)-1)]\n",
    "            synonyms = get_synonyms(random_word)\n",
    "            counter += 1\n",
    "        else:\n",
    "            random_word = \"\"\n",
    "\n",
    "        if counter >= 10:\n",
    "            return\n",
    "    \n",
    "    random_synonym = synonyms[0]\n",
    "    random_idx = random.randint(0, len(new_words)-1)\n",
    "    new_words.insert(random_idx, random_synonym)\n",
    "\n",
    "\n",
    "\n",
    "def EDA(sentence, alpha_sr=0.1, alpha_ri=0.1, alpha_rs=0.1, p_rd=0.1, num_aug=1):\n",
    "    sentence = get_only_hangul(sentence)\n",
    "    words = sentence.split(' ')\n",
    "    words = [word for word in words if word is not \"\"]\n",
    "    num_words = len(words)\n",
    "\n",
    "    augmented_sentences = []\n",
    "    num_new_per_technique = int(num_aug/4) + 1\n",
    "\n",
    "    n_sr = max(1, int(alpha_sr*num_words))\n",
    "    n_ri = max(1, int(alpha_ri*num_words))\n",
    "    n_rs = max(1, int(alpha_rs*num_words))\n",
    "\n",
    "    # sr\n",
    "    for _ in range(num_new_per_technique):\n",
    "        a_words = synonym_replacement(words, n_sr)\n",
    "        augmented_sentences.append(' '.join(a_words))\n",
    "\n",
    "    # ri\n",
    "    for _ in range(num_new_per_technique):\n",
    "        a_words = random_insertion(words, n_ri)\n",
    "        augmented_sentences.append(' '.join(a_words))\n",
    "\n",
    "    # rs\n",
    "    for _ in range(num_new_per_technique):\n",
    "        a_words = random_swap(words, n_rs)\n",
    "        augmented_sentences.append(\" \".join(a_words))\n",
    "\n",
    "    # rd\n",
    "    for _ in range(num_new_per_technique):\n",
    "        a_words = random_deletion(words, p_rd)\n",
    "        augmented_sentences.append(\" \".join(a_words))\n",
    "\n",
    "    augmented_sentences = [get_only_hangul(sentence) for sentence in augmented_sentences]\n",
    "    random.shuffle(augmented_sentences)\n",
    "\n",
    "    if num_aug >= 1:\n",
    "        augmented_sentences = augmented_sentences[:num_aug]\n",
    "    else:\n",
    "        keep_prob = num_aug / len(augmented_sentences)\n",
    "        augmented_sentences = [s for s in augmented_sentences if random.uniform(0, 1) < keep_prob]\n",
    "\n",
    "    augmented_sentences.append(sentence)\n",
    "\n",
    "    return augmented_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea320a6b",
   "metadata": {},
   "source": [
    "# 기존 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce2f0fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "231cb93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"kobert입력데이터.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6bccd0",
   "metadata": {},
   "source": [
    "## topic, document 컬럼 type 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70ca0223",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"topic\"] = data[\"topic\"].astype(str)\n",
    "data[\"document\"] = data[\"document\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a79f1976",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc50caea",
   "metadata": {},
   "source": [
    "## 비어있는 데이터프레임생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f56592a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adac3c2",
   "metadata": {},
   "source": [
    "## 생성 후 함수를 돌려 문서별로 쌓기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2ba448",
   "metadata": {},
   "source": [
    "* 각 단어를 9개씩 증가시켜 1개의 문서를 10개로 만들었다!!(이 과정을 10, 5, 2 배수로 해서 데이터 셋을 만들고 모델을 적합시키겠음!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcc31765",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(length) :\n",
    "        temp = pd.DataFrame()\n",
    "        text = EDA(data[\"clean_txt1\"][i])\n",
    "        l = len(text)\n",
    "        topic = [data[\"topic\"][i]]*l\n",
    "        document = [data[\"document\"][i]]*l\n",
    "        \n",
    "        temp[\"topic\"] = topic\n",
    "        temp[\"text\"] = text\n",
    "        temp[\"document\"] = document\n",
    "        \n",
    "        total =pd.concat([total,temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96a484a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = total.iloc[:, [2,0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae7cb48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = total.reset_index().iloc[:,[1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "669cd83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>topic</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>존경 지지 주택 전시관 입점 업체 임차인 주택 전시관 업체 심정 호소 강제 철거 업...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>존경 지지 주택 전시관 입점 업체 임차인 주택 전시관 업체 심정 호소 강제 철거 업...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>올해 여자 작년 치매 고생 사 엄마 하늘 식구 엄마 우울증 무기력 상태 연 풀칠 강...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>올해 여자 작년 치매 고생 엄마 하늘 식구 엄마 우울증 무기력 상태 풀칠 강아지 연...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>과학 고등학교 직전 학년 고등학교 선행 학습 학원 치열 주위 고등학교 국어 수학 학...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  document topic                                               text\n",
       "0        1    15  존경 지지 주택 전시관 입점 업체 임차인 주택 전시관 업체 심정 호소 강제 철거 업...\n",
       "1        1    15  존경 지지 주택 전시관 입점 업체 임차인 주택 전시관 업체 심정 호소 강제 철거 업...\n",
       "2        2     5  올해 여자 작년 치매 고생 사 엄마 하늘 식구 엄마 우울증 무기력 상태 연 풀칠 강...\n",
       "3        2     5  올해 여자 작년 치매 고생 엄마 하늘 식구 엄마 우울증 무기력 상태 풀칠 강아지 연...\n",
       "4        3    20  과학 고등학교 직전 학년 고등학교 선행 학습 학원 치열 주위 고등학교 국어 수학 학..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db96c780",
   "metadata": {},
   "source": [
    "## 완성된 데이터를 저장하자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f514d3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "total.to_csv(\"kobert데이터증강(n=2).csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278cba09",
   "metadata": {},
   "source": [
    "# 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4696c7",
   "metadata": {},
   "source": [
    "[1] [데이터증강기법 논문리뷰 블로그](https://catsirup.github.io/ai/2020/04/21/nlp_data_argumentation.html)\n",
    "\n",
    "[2] [데이터증강기법 코드](https://github.com/catSirup/KorEDA/tree/master)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "541.6px",
    "left": "917px",
    "top": "111.125px",
    "width": "303.837px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
